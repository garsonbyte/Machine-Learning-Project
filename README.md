# Machine Learning Project
To Do:  
- ***Format with text blocks (While we write the report)
- Bar Graphs (Comparing 4 algorithms: Logistic, SVM, PCA_Logistic, PCA_SVM) ->finished. 
- ***Confusion matrices (on python) -> finished. 
- ***Did we ever do linear regression with PCA? Nope. 

For SVM, any c value above 10^3 does not work. 
Paper: 
https://www.overleaf.com/1871767983rcmkbjwnhbnp
- Have not finished logistic regression 
- Conclusion 

Powerpoint: 
- Have not started 

Tables are completed! 
    Tables: 
        Linear Regression: 
            - Overall (final) results
            - Native Bayes 
            - L1 Regularization
            - L2 Regularization 
        SVM: 
            - Overall Results 
            - SVM with Linear Kernel (cVals, Precision, Fscore, Recall, Accuracy)
            - SVM with RBF
            - SVM with Polynomial 
        PCA: 
            - Overall Results 
            - Dimensionality vs Explained Variance
            - PCA with SVM results (cVals, Precision, Fscore, Recall, Accuracy)
            - PCA with logistic regression (with both Regularization and no Regularization)
            
If we have time: 
- Neural Networks 

?????? How does PCA relate to overfitting? 
- When we had 5 features, and added regularization it returned better results 
